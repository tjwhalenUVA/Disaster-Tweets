{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in Data\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "#Cleaning Data\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "\n",
    "#Model Building\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "db_pw = open('C:/Users/Jake/Documents/Projects/jakes_db.txt').read()\n",
    "\n",
    "engine = create_engine('postgresql://postgres:%s@localhost:5432/disaster' % db_pw)\n",
    "conn = engine.connect()\n",
    "\n",
    "train = pd.read_sql('SELECT * FROM train;', conn)\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a holdout test set from training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train['text'], train['target'], random_state=0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a class tokenizer to perform the lemmatize action on the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk import word_tokenize          \n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = nltk.WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in nltk.word_tokenize(articles)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pipeline for training and fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the pipeline\n",
    "rf_pipe = Pipeline([\n",
    "    ('tfidf_vec', TfidfVectorizer(tokenizer=LemmaTokenizer(), analyzer='word', stop_words = stopwords, strip_accents = 'ascii')),\n",
    "    ('clf',   RandomForestClassifier(criterion = 'gini', max_depth = None, min_samples_split = 10, max_features = 'log2'))\n",
    "])\n",
    "\n",
    "#try with TFIDF and stemming rather than lemmatizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a parameter grid to tune the RF model and search for the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  5.4min finished\n",
      "C:\\Users\\Jake\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "#Parameter Grid for Searching\n",
    "rf_param_grid = {\n",
    "    'tfidf_vec__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf_vec__max_df': [0.75, 0.9],\n",
    "    'tfidf_vec__min_df': [10, 20],\n",
    "    'clf__n_estimators': [25, 100, 250]\n",
    "}\n",
    "\n",
    "rf_cv = GridSearchCV(rf_pipe, rf_param_grid, n_jobs= -1, verbose=5, return_train_score=True)\n",
    "                  \n",
    "rf_cv_models = rf_cv.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__n_estimators': 250, 'tfidf_vec__max_df': 0.75, 'tfidf_vec__min_df': 10, 'tfidf_vec__ngram_range': (1, 1)}\n",
      "0.7829228243021346\n"
     ]
    }
   ],
   "source": [
    "print(rf_cv_models.best_params_)    \n",
    "print(rf_cv_models.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the top 5 models (based on accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__n_estimators</th>\n",
       "      <th>param_tfidf_vec__max_df</th>\n",
       "      <th>param_tfidf_vec__min_df</th>\n",
       "      <th>param_tfidf_vec__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.736946</td>\n",
       "      <td>0.064861</td>\n",
       "      <td>1.053868</td>\n",
       "      <td>0.028108</td>\n",
       "      <td>250</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__n_estimators': 250, 'tfidf_vec__max_df': 0.75, 'tfidf_vec__min_df': 10, 'tfidf_vec__ngram...</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.782923</td>\n",
       "      <td>0.007885</td>\n",
       "      <td>1</td>\n",
       "      <td>0.982348</td>\n",
       "      <td>0.980296</td>\n",
       "      <td>0.983785</td>\n",
       "      <td>0.981527</td>\n",
       "      <td>0.980501</td>\n",
       "      <td>0.981691</td>\n",
       "      <td>0.001281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8.872314</td>\n",
       "      <td>0.214473</td>\n",
       "      <td>1.284441</td>\n",
       "      <td>0.166380</td>\n",
       "      <td>250</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__n_estimators': 250, 'tfidf_vec__max_df': 0.9, 'tfidf_vec__min_df': 10, 'tfidf_vec__ngram_...</td>\n",
       "      <td>0.788998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.781117</td>\n",
       "      <td>0.004604</td>\n",
       "      <td>2</td>\n",
       "      <td>0.983169</td>\n",
       "      <td>0.979680</td>\n",
       "      <td>0.982553</td>\n",
       "      <td>0.981117</td>\n",
       "      <td>0.979475</td>\n",
       "      <td>0.981199</td>\n",
       "      <td>0.001484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.291637</td>\n",
       "      <td>0.061668</td>\n",
       "      <td>0.945272</td>\n",
       "      <td>0.023495</td>\n",
       "      <td>100</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__n_estimators': 100, 'tfidf_vec__max_df': 0.75, 'tfidf_vec__min_df': 10, 'tfidf_vec__ngram...</td>\n",
       "      <td>0.784893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.780788</td>\n",
       "      <td>0.005943</td>\n",
       "      <td>3</td>\n",
       "      <td>0.981527</td>\n",
       "      <td>0.978654</td>\n",
       "      <td>0.979269</td>\n",
       "      <td>0.978859</td>\n",
       "      <td>0.979269</td>\n",
       "      <td>0.979516</td>\n",
       "      <td>0.001034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.075155</td>\n",
       "      <td>0.036021</td>\n",
       "      <td>0.942256</td>\n",
       "      <td>0.040764</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__n_estimators': 100, 'tfidf_vec__max_df': 0.9, 'tfidf_vec__min_df': 10, 'tfidf_vec__ngram_...</td>\n",
       "      <td>0.793924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.780624</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>4</td>\n",
       "      <td>0.981322</td>\n",
       "      <td>0.979475</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.979064</td>\n",
       "      <td>0.979885</td>\n",
       "      <td>0.980501</td>\n",
       "      <td>0.001362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7.974532</td>\n",
       "      <td>0.069731</td>\n",
       "      <td>1.078106</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>250</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__n_estimators': 250, 'tfidf_vec__max_df': 0.75, 'tfidf_vec__min_df': 10, 'tfidf_vec__ngram...</td>\n",
       "      <td>0.787356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777504</td>\n",
       "      <td>0.006506</td>\n",
       "      <td>5</td>\n",
       "      <td>0.981938</td>\n",
       "      <td>0.979680</td>\n",
       "      <td>0.982348</td>\n",
       "      <td>0.979475</td>\n",
       "      <td>0.978859</td>\n",
       "      <td>0.980460</td>\n",
       "      <td>0.001407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "16       7.736946      0.064861         1.053868        0.028108   \n",
       "20       8.872314      0.214473         1.284441        0.166380   \n",
       "8        5.291637      0.061668         0.945272        0.023495   \n",
       "12       5.075155      0.036021         0.942256        0.040764   \n",
       "17       7.974532      0.069731         1.078106        0.009888   \n",
       "\n",
       "   param_clf__n_estimators param_tfidf_vec__max_df param_tfidf_vec__min_df  \\\n",
       "16                     250                    0.75                      10   \n",
       "20                     250                     0.9                      10   \n",
       "8                      100                    0.75                      10   \n",
       "12                     100                     0.9                      10   \n",
       "17                     250                    0.75                      10   \n",
       "\n",
       "   param_tfidf_vec__ngram_range  \\\n",
       "16                       (1, 1)   \n",
       "20                       (1, 1)   \n",
       "8                        (1, 1)   \n",
       "12                       (1, 1)   \n",
       "17                       (1, 2)   \n",
       "\n",
       "                                                                                                 params  \\\n",
       "16  {'clf__n_estimators': 250, 'tfidf_vec__max_df': 0.75, 'tfidf_vec__min_df': 10, 'tfidf_vec__ngram...   \n",
       "20  {'clf__n_estimators': 250, 'tfidf_vec__max_df': 0.9, 'tfidf_vec__min_df': 10, 'tfidf_vec__ngram_...   \n",
       "8   {'clf__n_estimators': 100, 'tfidf_vec__max_df': 0.75, 'tfidf_vec__min_df': 10, 'tfidf_vec__ngram...   \n",
       "12  {'clf__n_estimators': 100, 'tfidf_vec__max_df': 0.9, 'tfidf_vec__min_df': 10, 'tfidf_vec__ngram_...   \n",
       "17  {'clf__n_estimators': 250, 'tfidf_vec__max_df': 0.75, 'tfidf_vec__min_df': 10, 'tfidf_vec__ngram...   \n",
       "\n",
       "    split0_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       "16           0.791461  ...         0.782923        0.007885                1   \n",
       "20           0.788998  ...         0.781117        0.004604                2   \n",
       "8            0.784893  ...         0.780788        0.005943                3   \n",
       "12           0.793924  ...         0.780624        0.008034                4   \n",
       "17           0.787356  ...         0.777504        0.006506                5   \n",
       "\n",
       "    split0_train_score  split1_train_score  split2_train_score  \\\n",
       "16            0.982348            0.980296            0.983785   \n",
       "20            0.983169            0.979680            0.982553   \n",
       "8             0.981527            0.978654            0.979269   \n",
       "12            0.981322            0.979475            0.982759   \n",
       "17            0.981938            0.979680            0.982348   \n",
       "\n",
       "    split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "16            0.981527            0.980501          0.981691         0.001281  \n",
       "20            0.981117            0.979475          0.981199         0.001484  \n",
       "8             0.978859            0.979269          0.979516         0.001034  \n",
       "12            0.979064            0.979885          0.980501         0.001362  \n",
       "17            0.979475            0.978859          0.980460         0.001407  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_gs_results = pd.DataFrame(rf_cv_models.cv_results_).sort_values('mean_test_score', ascending=False)\n",
    "rf_gs_results[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save all model results and save best model for use in a later notebook comparing different classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/Jake/Documents/Projects/Disaster-Tweets/models/random_forest/rf_best.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model_dir = 'C:/Users/Jake/Documents/Projects/Disaster-Tweets/models/random_forest'\n",
    "rf_gs_results.to_excel(rf_model_dir + '/rf_gs_results.xlsx', index=False)\n",
    "\n",
    "dump(rf_cv_models.best_estimator_, rf_model_dir + '/rf_best.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_model = load(rf_model_dir + '/rf_best.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate best models precision and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.81 / Recall: 0.654 / Accuracy: 0.801\n"
     ]
    }
   ],
   "source": [
    "# test the classifier\n",
    "rf_predict = rf_best_model.predict(X_test)\n",
    "precision, recall, fscore, support = score(y_test, rf_predict, average='binary')\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3),\n",
    "                                                        round(recall, 3),\n",
    "                                                        round((rf_predict==y_test).sum() / len(rf_predict),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_pipe = Pipeline([\n",
    "    ('tfidf_vec', TfidfVectorizer(tokenizer=LemmaTokenizer(), analyzer='word', stop_words = stopwords, strip_accents = 'ascii')),\n",
    "    ('clf',   GradientBoostingClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a parameter grid to tune the GB model and search for the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   31.4s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 18.1min finished\n",
      "C:\\Users\\Jake\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "#Parameter Grid for Searching\n",
    "gb_param_grid = {\n",
    "    'tfidf_vec__ngram_range': [(1,1), (1,2)],\n",
    "    'tfidf_vec__max_df': [0.75, 0.9],\n",
    "    'tfidf_vec__min_df': [10, 20],\n",
    "#     'tfidf_vec__norm': ['l1', 'l2'],\n",
    "#     'tfidf_vec__use_idf': [True, False],\n",
    "#     'tfidf_vec__sublinear_tf': [True, False],\n",
    "#     'tfidf_vec__smooth_idf': [True, False],\n",
    "#     'clf__loss': ['deviance', 'exponential'],\n",
    "#     'clf__learning_rate': [0.05, 0.1, 0.15],\n",
    "    'clf__n_estimators': [50, 100, 200],\n",
    "#     'clf__subsample': [1, 0.9],\n",
    "#     'clf__criterion': ['friedman_mse', 'mse', 'mae'],\n",
    "    'clf__max_depth': [2, 5, 10]\n",
    "}\n",
    "\n",
    "gb_cv = GridSearchCV(gb_pipe, gb_param_grid, n_jobs= -1, verbose=5, return_train_score=True)\n",
    "                  \n",
    "gb_cv_models = gb_cv.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__max_depth': 10, 'clf__n_estimators': 200, 'tfidf_vec__max_df': 0.9, 'tfidf_vec__min_df': 10, 'tfidf_vec__ngram_range': (1, 2)}\n",
      "0.7692939244663383\n"
     ]
    }
   ],
   "source": [
    "print(gb_cv_models.best_params_)    \n",
    "print(gb_cv_models.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the top 5 models (based on accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__max_depth</th>\n",
       "      <th>param_clf__n_estimators</th>\n",
       "      <th>param_tfidf_vec__max_df</th>\n",
       "      <th>param_tfidf_vec__min_df</th>\n",
       "      <th>param_tfidf_vec__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>18.656856</td>\n",
       "      <td>0.081469</td>\n",
       "      <td>0.869072</td>\n",
       "      <td>0.007993</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__max_depth': 10, 'clf__n_estimators': 200, 'tfidf_vec__max_df': 0.9, 'tfidf_vec__min_df': ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769294</td>\n",
       "      <td>0.008812</td>\n",
       "      <td>1</td>\n",
       "      <td>0.955665</td>\n",
       "      <td>0.955049</td>\n",
       "      <td>0.958539</td>\n",
       "      <td>0.955460</td>\n",
       "      <td>0.956486</td>\n",
       "      <td>0.956240</td>\n",
       "      <td>0.001241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>18.688061</td>\n",
       "      <td>0.032719</td>\n",
       "      <td>0.871919</td>\n",
       "      <td>0.031845</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__max_depth': 10, 'clf__n_estimators': 200, 'tfidf_vec__max_df': 0.75, 'tfidf_vec__min_df':...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768966</td>\n",
       "      <td>0.004970</td>\n",
       "      <td>2</td>\n",
       "      <td>0.958744</td>\n",
       "      <td>0.952997</td>\n",
       "      <td>0.957512</td>\n",
       "      <td>0.954433</td>\n",
       "      <td>0.956486</td>\n",
       "      <td>0.956034</td>\n",
       "      <td>0.002075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>15.931680</td>\n",
       "      <td>0.065996</td>\n",
       "      <td>0.840712</td>\n",
       "      <td>0.030295</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__max_depth': 10, 'clf__n_estimators': 200, 'tfidf_vec__max_df': 0.75, 'tfidf_vec__min_df':...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768801</td>\n",
       "      <td>0.008088</td>\n",
       "      <td>3</td>\n",
       "      <td>0.954639</td>\n",
       "      <td>0.951970</td>\n",
       "      <td>0.957718</td>\n",
       "      <td>0.956281</td>\n",
       "      <td>0.952791</td>\n",
       "      <td>0.954680</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>10.847158</td>\n",
       "      <td>0.033341</td>\n",
       "      <td>0.850061</td>\n",
       "      <td>0.007650</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__max_depth': 5, 'clf__n_estimators': 200, 'tfidf_vec__max_df': 0.9, 'tfidf_vec__min_df': 1...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768801</td>\n",
       "      <td>0.005510</td>\n",
       "      <td>3</td>\n",
       "      <td>0.888547</td>\n",
       "      <td>0.890394</td>\n",
       "      <td>0.893268</td>\n",
       "      <td>0.894704</td>\n",
       "      <td>0.889573</td>\n",
       "      <td>0.891297</td>\n",
       "      <td>0.002317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>10.840908</td>\n",
       "      <td>0.042381</td>\n",
       "      <td>0.878142</td>\n",
       "      <td>0.031890</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__max_depth': 5, 'clf__n_estimators': 200, 'tfidf_vec__max_df': 0.75, 'tfidf_vec__min_df': ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768473</td>\n",
       "      <td>0.006253</td>\n",
       "      <td>5</td>\n",
       "      <td>0.893062</td>\n",
       "      <td>0.887110</td>\n",
       "      <td>0.893473</td>\n",
       "      <td>0.895320</td>\n",
       "      <td>0.886494</td>\n",
       "      <td>0.891092</td>\n",
       "      <td>0.003590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "69      18.656856      0.081469         0.869072        0.007993   \n",
       "65      18.688061      0.032719         0.871919        0.031845   \n",
       "64      15.931680      0.065996         0.840712        0.030295   \n",
       "45      10.847158      0.033341         0.850061        0.007650   \n",
       "41      10.840908      0.042381         0.878142        0.031890   \n",
       "\n",
       "   param_clf__max_depth param_clf__n_estimators param_tfidf_vec__max_df  \\\n",
       "69                   10                     200                     0.9   \n",
       "65                   10                     200                    0.75   \n",
       "64                   10                     200                    0.75   \n",
       "45                    5                     200                     0.9   \n",
       "41                    5                     200                    0.75   \n",
       "\n",
       "   param_tfidf_vec__min_df param_tfidf_vec__ngram_range  \\\n",
       "69                      10                       (1, 2)   \n",
       "65                      10                       (1, 2)   \n",
       "64                      10                       (1, 1)   \n",
       "45                      10                       (1, 2)   \n",
       "41                      10                       (1, 2)   \n",
       "\n",
       "                                                                                                 params  \\\n",
       "69  {'clf__max_depth': 10, 'clf__n_estimators': 200, 'tfidf_vec__max_df': 0.9, 'tfidf_vec__min_df': ...   \n",
       "65  {'clf__max_depth': 10, 'clf__n_estimators': 200, 'tfidf_vec__max_df': 0.75, 'tfidf_vec__min_df':...   \n",
       "64  {'clf__max_depth': 10, 'clf__n_estimators': 200, 'tfidf_vec__max_df': 0.75, 'tfidf_vec__min_df':...   \n",
       "45  {'clf__max_depth': 5, 'clf__n_estimators': 200, 'tfidf_vec__max_df': 0.9, 'tfidf_vec__min_df': 1...   \n",
       "41  {'clf__max_depth': 5, 'clf__n_estimators': 200, 'tfidf_vec__max_df': 0.75, 'tfidf_vec__min_df': ...   \n",
       "\n",
       "    ...  mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "69  ...         0.769294        0.008812                1            0.955665   \n",
       "65  ...         0.768966        0.004970                2            0.958744   \n",
       "64  ...         0.768801        0.008088                3            0.954639   \n",
       "45  ...         0.768801        0.005510                3            0.888547   \n",
       "41  ...         0.768473        0.006253                5            0.893062   \n",
       "\n",
       "    split1_train_score  split2_train_score  split3_train_score  \\\n",
       "69            0.955049            0.958539            0.955460   \n",
       "65            0.952997            0.957512            0.954433   \n",
       "64            0.951970            0.957718            0.956281   \n",
       "45            0.890394            0.893268            0.894704   \n",
       "41            0.887110            0.893473            0.895320   \n",
       "\n",
       "    split4_train_score  mean_train_score  std_train_score  \n",
       "69            0.956486          0.956240         0.001241  \n",
       "65            0.956486          0.956034         0.002075  \n",
       "64            0.952791          0.954680         0.002131  \n",
       "45            0.889573          0.891297         0.002317  \n",
       "41            0.886494          0.891092         0.003590  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_gs_results = pd.DataFrame(gb_cv_models.cv_results_).sort_values('mean_test_score', ascending=False)\n",
    "gb_gs_results[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save all model results and save best model for use in a later notebook comparing different classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/Jake/Documents/Projects/Disaster-Tweets/models/gradient_boost/gb_best.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_model_dir = 'C:/Users/Jake/Documents/Projects/Disaster-Tweets/models/gradient_boost'\n",
    "gb_gs_results.to_excel(gb_model_dir + '/gb_gs_results.xlsx', index=False)\n",
    "\n",
    "dump(gb_cv_models.best_estimator_, gb_model_dir + '/gb_best.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_best_model = load(gb_model_dir + '/gb_best.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate best models precision and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.773 / Recall: 0.667 / Accuracy: 0.789\n"
     ]
    }
   ],
   "source": [
    "# test the classifier\n",
    "gb_predict = gb_best_model.predict(X_test)\n",
    "precision, recall, fscore, support = score(y_test, gb_predict, average='binary')\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3),\n",
    "                                                        round(recall, 3),\n",
    "                                                        round((gb_predict==y_test).sum() / len(gb_predict),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp] *",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
